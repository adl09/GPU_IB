{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adl09/GPU_IB/blob/main/Clase1/ICNPG_AddTwoVectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suma de dos vectores: CUDA-C vs C\n",
        "\n",
        "Nuevamente vamos a analizar el caso simple, vergonzosamente paralelo, de sumar dos vectores grandes."
      ],
      "metadata": {
        "id": "gvOZXUbW-717"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N (1 << 24)  // Vector size: 16 million elements\n",
        "\n",
        "// GPU Kernel for vector addition\n",
        "__global__ void vectorAddGPU(float* a, float* b, float* c, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CPU function for vector addition\n",
        "void vectorAddCPU(float* a, float* b, float* c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *h_a, *h_b, *h_c, *d_a, *d_b, *d_c;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    h_a = (float*)malloc(size);\n",
        "    h_b = (float*)malloc(size);\n",
        "    h_c = (float*)malloc(size);\n",
        "\n",
        "    // Initialize vectors with random values\n",
        "    srand(time(0));\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_a[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_b[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_c[i] = 0.0f;\n",
        "    }\n",
        "\n",
        "    // -------------------- CPU Computation --------------------\n",
        "    clock_t start_cpu = clock();\n",
        "    vectorAddCPU(h_a, h_b, h_c, N);\n",
        "    clock_t end_cpu = clock();\n",
        "    double cpu_time = double(end_cpu - start_cpu) / CLOCKS_PER_SEC;\n",
        "    std::cout << \"CPU Time: \" << cpu_time << \" sec\" << std::endl;\n",
        "\n",
        "    // -------------------- GPU Computation --------------------\n",
        "    cudaMalloc((void**)&d_a, size);\n",
        "    cudaMalloc((void**)&d_b, size);\n",
        "    cudaMalloc((void**)&d_c, size);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define execution configuration\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    vectorAddGPU<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "      std::cerr << \"CUDA Kernel Error: \" << cudaGetErrorString(err) << std::endl;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_time;\n",
        "    cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "    std::cout << \"GPU Time: \" << gpu_time / 1000.0 << \" sec\" << std::endl;\n",
        "\n",
        "    std::cout << \"Speedup: \" << cpu_time/(gpu_time / 1000.0) << \"x\" << std::endl;\n",
        "\n",
        "    // Compare results (basic check)\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        std::cout << \"h_a[\" << i << \"] = \" << h_a[i] << \", h_b[\" << i << \"] = \" << h_b[i] << \", h_c[\" << i << \"] = \" << h_c[i] << std::endl;\n",
        "        if (fabs(h_c[i] - (h_a[i] + h_b[i])) > 1e-3) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    std::cout << (correct ? \"Results match!\" : \"Results mismatch!\") << std::endl;\n",
        "\n",
        "    // Free memory\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjQ1HZeSGuv9",
        "outputId": "38cfc7d6-0a27-43bd-975b-812168baf93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 add.cu -o add  # Replace with actual compute capability"
      ],
      "metadata": {
        "id": "9m6QiFA2HgOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "correr mas de una vez el ejecutable, ya que los tiempos pueden fluctuar..."
      ],
      "metadata": {
        "id": "nubrZprZRRs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX-xLO3pHpc9",
        "outputId": "f194fcaf-e0d3-4a5f-ca26-c62b1a66f434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time: 0.053869 sec\n",
            "GPU Time: 0.000825728 sec\n",
            "Speedup: 65.2382x\n",
            "h_a[0] = 0.237654, h_b[0] = 0.182163, h_c[0] = 0.419817\n",
            "h_a[1] = 0.912545, h_b[1] = 0.572565, h_c[1] = 1.48511\n",
            "h_a[2] = 0.17243, h_b[2] = 0.700801, h_c[2] = 0.87323\n",
            "h_a[3] = 0.0264569, h_b[3] = 0.0748017, h_c[3] = 0.101259\n",
            "h_a[4] = 0.0439108, h_b[4] = 0.27758, h_c[4] = 0.321491\n",
            "h_a[5] = 0.602988, h_b[5] = 0.0305977, h_c[5] = 0.633586\n",
            "h_a[6] = 0.265353, h_b[6] = 0.0199901, h_c[6] = 0.285343\n",
            "h_a[7] = 0.855656, h_b[7] = 0.364489, h_c[7] = 1.22014\n",
            "h_a[8] = 0.161729, h_b[8] = 0.2209, h_c[8] = 0.382629\n",
            "h_a[9] = 0.166313, h_b[9] = 0.452484, h_c[9] = 0.618798\n",
            "Results match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea\n",
        "\n",
        "1. Modificar el programa anterior para que acepte $N$ como input, calcule el tiempo de la suma en GPU y CPU, t_suma_GPU y t_suma_CPU respectivamente, y el tiempo de la suma mas la copia H2D y D2H en GPU, t_total_GPU.\n",
        "\n",
        "2. Generar un archivo de dos columnas:\n",
        "\n",
        "\n",
        "  | N | t_suma_CPU | t_suma_GPU | t_total_GPU |\n",
        "  |----------|----------|----------|----------|\n",
        "  | 1000   | Data 2   | Data 3   | Data 4   |\n",
        "  | 10000   | Data 2   | Data 3   | Data 4   |\n",
        "  | 100000   | Data 2   | Data 3   | Data 4   |\n",
        "  | 1000000   | Data 2   | Data 3   | Data 4   |\n",
        "  | 10000000   | Data 2   | Data 3   | Data 4   |\n",
        "  | ...   | Data 2   | Data 3   | Data 4   |\n",
        "  | ¿cual es el limite?   | Data 2   | Data 4   | Data 3   |\n",
        "\n",
        "  donde\n",
        "\n",
        "  * t_suma es el tiempo solo de la suma\n",
        "  * t_total es el tiempo de la suma mas el tiempo de las copias H2D y D2H.\n",
        "\n",
        "2. Graficar todos los tiempos vs $N$, analizar como escalean, y discutir.\n",
        "\n",
        "3. Modificar el código para que calcule $x[i]=a*x[i]+y[i]$, donde $a$ es una constante. Este algoritmo se llama SAXPY (la S es de single precision, otras variantes para precision doble o enteros son DAXPY o AXPY).\n",
        "\n",
        "4. Cambiar la configuración de la grilla: ¿$N$ bloques de un hilo? ¿Un bloque con $N$ hilos?\n",
        "\n",
        "5. ¿Qué sucede si eliminamos los CudaDeviceSynchronize()?"
      ],
      "metadata": {
        "id": "IdE9COuMAQJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling\n",
        "\n",
        "Un profiling básico del código CUDA se obtiene usando el comando \"nvprof\""
      ],
      "metadata": {
        "id": "KTiXBPdUFLir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47t1iGuOFPSO",
        "outputId": "b454d6d7-355b-46be-f1d1-a8ce109987ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time: 0.054392 sec\n",
            "==6069== NVPROF is profiling process 6069, command: ./add\n",
            "GPU Time: 0.000873312 sec\n",
            "Speedup: 62.2824x\n",
            "h_a[0] = 0.373852, h_b[0] = 0.823837, h_c[0] = 1.19769\n",
            "h_a[1] = 0.188026, h_b[1] = 0.537949, h_c[1] = 0.725975\n",
            "h_a[2] = 0.140692, h_b[2] = 0.47351, h_c[2] = 0.614202\n",
            "h_a[3] = 0.743308, h_b[3] = 0.782842, h_c[3] = 1.52615\n",
            "h_a[4] = 0.670559, h_b[4] = 0.634817, h_c[4] = 1.30538\n",
            "h_a[5] = 0.135769, h_b[5] = 0.466437, h_c[5] = 0.602206\n",
            "h_a[6] = 0.417194, h_b[6] = 0.757118, h_c[6] = 1.17431\n",
            "h_a[7] = 0.128106, h_b[7] = 0.500637, h_c[7] = 0.628742\n",
            "h_a[8] = 0.790354, h_b[8] = 0.921458, h_c[8] = 1.71181\n",
            "h_a[9] = 0.406634, h_b[9] = 0.921733, h_c[9] = 1.32837\n",
            "Results match!\n",
            "==6069== Profiling application: ./add\n",
            "==6069== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   64.52%  28.247ms         2  14.123ms  14.106ms  14.141ms  [CUDA memcpy HtoD]\n",
            "                   33.72%  14.762ms         1  14.762ms  14.762ms  14.762ms  [CUDA memcpy DtoH]\n",
            "                    1.77%  774.48us         1  774.48us  774.48us  774.48us  vectorAddGPU(float*, float*, float*, int)\n",
            "      API calls:   62.20%  79.624ms         3  26.541ms  90.069us  79.425ms  cudaMalloc\n",
            "                   34.82%  44.576ms         3  14.859ms  14.272ms  15.932ms  cudaMemcpy\n",
            "                    2.70%  3.4520ms         3  1.1507ms  213.36us  2.1167ms  cudaFree\n",
            "                    0.12%  150.87us         1  150.87us  150.87us  150.87us  cudaLaunchKernel\n",
            "                    0.11%  144.25us       114  1.2650us     108ns  59.357us  cuDeviceGetAttribute\n",
            "                    0.01%  16.951us         2  8.4750us     939ns  16.012us  cudaEventCreate\n",
            "                    0.01%  13.236us         1  13.236us  13.236us  13.236us  cuDeviceGetName\n",
            "                    0.01%  10.690us         2  5.3450us  4.2500us  6.4400us  cudaEventRecord\n",
            "                    0.00%  5.2180us         1  5.2180us  5.2180us  5.2180us  cudaDeviceSynchronize\n",
            "                    0.00%  5.0000us         1  5.0000us  5.0000us  5.0000us  cudaEventSynchronize\n",
            "                    0.00%  4.6830us         1  4.6830us  4.6830us  4.6830us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.6240us         1  2.6240us  2.6240us  2.6240us  cudaEventElapsedTime\n",
            "                    0.00%  1.5020us         3     500ns     133ns  1.2070us  cuDeviceGetCount\n",
            "                    0.00%  1.0780us         2     539ns     139ns     939ns  cuDeviceGet\n",
            "                    0.00%     380ns         1     380ns     380ns     380ns  cuDeviceTotalMem\n",
            "                    0.00%     379ns         1     379ns     379ns     379ns  cudaGetLastError\n",
            "                    0.00%     357ns         1     357ns     357ns     357ns  cuModuleGetLoadingMode\n",
            "                    0.00%     314ns         1     314ns     314ns     314ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gprof para CPU\n",
        "Uno equivalente para CPU es el gprof"
      ],
      "metadata": {
        "id": "0n3ADmAVF3Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sumacpu.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <fstream>\n",
        "\n",
        "\n",
        "// CPU function for vector addition\n",
        "void vectorAddCPU(float* a, float* b, float* c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    int N=16777216;\n",
        "    float *h_a, *h_b, *h_c;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    h_a = (float*)malloc(size);\n",
        "    h_b = (float*)malloc(size);\n",
        "    h_c = (float*)malloc(size);\n",
        "\n",
        "    // Initialize vectors with random values\n",
        "    srand(time(0));\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_a[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_b[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_c[i] = 0.0f;\n",
        "    }\n",
        "\n",
        "    // -------------------- CPU Computation --------------------\n",
        "    clock_t start_cpu = clock();\n",
        "    vectorAddCPU(h_a, h_b, h_c, N);\n",
        "    clock_t end_cpu = clock();\n",
        "    double cpu_time = double(end_cpu - start_cpu) / CLOCKS_PER_SEC;\n",
        "    std::cout << \"CPU Time: \" << cpu_time << \" sec\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnbO5q8PF7MW",
        "outputId": "51d0abbc-1710-4f46-a888-29e70d874de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sumacpu.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ -pg sumacpu.cpp -o sumacpu; ./sumacpu; echo \"############\"; gprof ./sumacpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BIOBkJxGQFF",
        "outputId": "07ea44f6-9b22-4a7e-ffed-fa040c7c62ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time: 0.057967 sec\n",
            "############\n",
            "Flat profile:\n",
            "\n",
            "Each sample counts as 0.01 seconds.\n",
            "  %   cumulative   self              self     total           \n",
            " time   seconds   seconds    calls  ms/call  ms/call  name    \n",
            " 73.08      0.19     0.19                             main\n",
            " 19.23      0.24     0.05        1    50.00    50.00  vectorAddCPU(float*, float*, float*, int)\n",
            "  7.69      0.26     0.02                             _init\n",
            "  0.00      0.26     0.00        1     0.00     0.00  __static_initialization_and_destruction_0(int, int)\n",
            "\n",
            " %         the percentage of the total running time of the\n",
            "time       program used by this function.\n",
            "\n",
            "cumulative a running sum of the number of seconds accounted\n",
            " seconds   for by this function and those listed above it.\n",
            "\n",
            " self      the number of seconds accounted for by this\n",
            "seconds    function alone.  This is the major sort for this\n",
            "           listing.\n",
            "\n",
            "calls      the number of times this function was invoked, if\n",
            "           this function is profiled, else blank.\n",
            "\n",
            " self      the average number of milliseconds spent in this\n",
            "ms/call    function per call, if this function is profiled,\n",
            "\t   else blank.\n",
            "\n",
            " total     the average number of milliseconds spent in this\n",
            "ms/call    function and its descendents per call, if this\n",
            "\t   function is profiled, else blank.\n",
            "\n",
            "name       the name of the function.  This is the minor sort\n",
            "           for this listing. The index shows the location of\n",
            "\t   the function in the gprof listing. If the index is\n",
            "\t   in parenthesis it shows where it would appear in\n",
            "\t   the gprof listing if it were to be printed.\n",
            "\f\n",
            "Copyright (C) 2012-2022 Free Software Foundation, Inc.\n",
            "\n",
            "Copying and distribution of this file, with or without modification,\n",
            "are permitted in any medium without royalty provided the copyright\n",
            "notice and this notice are preserved.\n",
            "\f\n",
            "\t\t     Call graph (explanation follows)\n",
            "\n",
            "\n",
            "granularity: each sample hit covers 4 byte(s) for 3.85% of 0.26 seconds\n",
            "\n",
            "index % time    self  children    called     name\n",
            "                                                 <spontaneous>\n",
            "[1]     92.3    0.19    0.05                 main [1]\n",
            "                0.05    0.00       1/1           vectorAddCPU(float*, float*, float*, int) [2]\n",
            "-----------------------------------------------\n",
            "                0.05    0.00       1/1           main [1]\n",
            "[2]     19.2    0.05    0.00       1         vectorAddCPU(float*, float*, float*, int) [2]\n",
            "-----------------------------------------------\n",
            "                                                 <spontaneous>\n",
            "[3]      7.7    0.02    0.00                 _init [3]\n",
            "-----------------------------------------------\n",
            "                0.00    0.00       1/1           _GLOBAL__sub_I__Z12vectorAddCPUPfS_S_i [11]\n",
            "[10]     0.0    0.00    0.00       1         __static_initialization_and_destruction_0(int, int) [10]\n",
            "-----------------------------------------------\n",
            "\n",
            " This table describes the call tree of the program, and was sorted by\n",
            " the total amount of time spent in each function and its children.\n",
            "\n",
            " Each entry in this table consists of several lines.  The line with the\n",
            " index number at the left hand margin lists the current function.\n",
            " The lines above it list the functions that called this function,\n",
            " and the lines below it list the functions this one called.\n",
            " This line lists:\n",
            "     index\tA unique number given to each element of the table.\n",
            "\t\tIndex numbers are sorted numerically.\n",
            "\t\tThe index number is printed next to every function name so\n",
            "\t\tit is easier to look up where the function is in the table.\n",
            "\n",
            "     % time\tThis is the percentage of the `total' time that was spent\n",
            "\t\tin this function and its children.  Note that due to\n",
            "\t\tdifferent viewpoints, functions excluded by options, etc,\n",
            "\t\tthese numbers will NOT add up to 100%.\n",
            "\n",
            "     self\tThis is the total amount of time spent in this function.\n",
            "\n",
            "     children\tThis is the total amount of time propagated into this\n",
            "\t\tfunction by its children.\n",
            "\n",
            "     called\tThis is the number of times the function was called.\n",
            "\t\tIf the function called itself recursively, the number\n",
            "\t\tonly includes non-recursive calls, and is followed by\n",
            "\t\ta `+' and the number of recursive calls.\n",
            "\n",
            "     name\tThe name of the current function.  The index number is\n",
            "\t\tprinted after it.  If the function is a member of a\n",
            "\t\tcycle, the cycle number is printed between the\n",
            "\t\tfunction's name and the index number.\n",
            "\n",
            "\n",
            " For the function's parents, the fields have the following meanings:\n",
            "\n",
            "     self\tThis is the amount of time that was propagated directly\n",
            "\t\tfrom the function into this parent.\n",
            "\n",
            "     children\tThis is the amount of time that was propagated from\n",
            "\t\tthe function's children into this parent.\n",
            "\n",
            "     called\tThis is the number of times this parent called the\n",
            "\t\tfunction `/' the total number of times the function\n",
            "\t\twas called.  Recursive calls to the function are not\n",
            "\t\tincluded in the number after the `/'.\n",
            "\n",
            "     name\tThis is the name of the parent.  The parent's index\n",
            "\t\tnumber is printed after it.  If the parent is a\n",
            "\t\tmember of a cycle, the cycle number is printed between\n",
            "\t\tthe name and the index number.\n",
            "\n",
            " If the parents of the function cannot be determined, the word\n",
            " `<spontaneous>' is printed in the `name' field, and all the other\n",
            " fields are blank.\n",
            "\n",
            " For the function's children, the fields have the following meanings:\n",
            "\n",
            "     self\tThis is the amount of time that was propagated directly\n",
            "\t\tfrom the child into the function.\n",
            "\n",
            "     children\tThis is the amount of time that was propagated from the\n",
            "\t\tchild's children to the function.\n",
            "\n",
            "     called\tThis is the number of times the function called\n",
            "\t\tthis child `/' the total number of times the child\n",
            "\t\twas called.  Recursive calls by the child are not\n",
            "\t\tlisted in the number after the `/'.\n",
            "\n",
            "     name\tThis is the name of the child.  The child's index\n",
            "\t\tnumber is printed after it.  If the child is a\n",
            "\t\tmember of a cycle, the cycle number is printed\n",
            "\t\tbetween the name and the index number.\n",
            "\n",
            " If there are any cycles (circles) in the call graph, there is an\n",
            " entry for the cycle-as-a-whole.  This entry shows who called the\n",
            " cycle (as parents) and the members of the cycle (as children.)\n",
            " The `+' recursive calls entry shows the number of function calls that\n",
            " were internal to the cycle, and the calls entry for each member shows,\n",
            " for that member, how many times it was called from other members of\n",
            " the cycle.\n",
            "\f\n",
            "Copyright (C) 2012-2022 Free Software Foundation, Inc.\n",
            "\n",
            "Copying and distribution of this file, with or without modification,\n",
            "are permitted in any medium without royalty provided the copyright\n",
            "notice and this notice are preserved.\n",
            "\f\n",
            "Index by function name\n",
            "\n",
            "   [2] vectorAddCPU(float*, float*, float*, int) [3] _init\n",
            "  [10] __static_initialization_and_destruction_0(int, int) [1] main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suma de vectores en CUDA pyhton, usando cupy"
      ],
      "metadata": {
        "id": "N8PDGUA__yR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ya veremos en mas detalle CUDA python, pero este ejemplo ya da una idea, usando cupy en esta oportunidad."
      ],
      "metadata": {
        "id": "vyBB41BmS4S5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una forma es usar CUDA C para el kernel, y cupy y numpy vectors para el manejor de la memoria."
      ],
      "metadata": {
        "id": "rD_MCWLdV8As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "\n",
        "ker = cp.RawKernel(r'''\n",
        "extern \"C\" __global__\n",
        "void vector_add(const float *a, const float *b, float *c, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "''', 'vector_add')\n",
        "\n",
        "N = 16777216\n",
        "a = cp.random.rand(N, dtype=cp.float32)\n",
        "b = cp.random.rand(N, dtype=cp.float32)\n",
        "c = cp.empty_like(a)\n",
        "\n",
        "threads_per_block = 256\n",
        "blocks_per_grid = (N + threads_per_block - 1) // threads_per_block\n",
        "\n",
        "cp.cuda.Device(0).synchronize()\n",
        "start = cp.cuda.Event()\n",
        "end = cp.cuda.Event()\n",
        "\n",
        "start.record()\n",
        "ker((blocks_per_grid,), (threads_per_block,), (a, b, c, N))\n",
        "end.record()\n",
        "end.synchronize()\n",
        "\n",
        "print(f\"CuPy RawKernel Execution Time: {cp.cuda.get_elapsed_time(start, end) / 1000:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5oUiv41V3nW",
        "outputId": "452673e2-4951-4cae-e3ad-e4dc35591ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CuPy RawKernel Execution Time: 0.036682 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como el kernel es muy simple, hay formas de evitar su escritura usando funciones u operadores de cupy."
      ],
      "metadata": {
        "id": "s7mwJx2THwK-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIzVkpmXGsBp",
        "outputId": "772d8ef4-9275-4859-c33f-6489fe508254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N: 16777216\n",
            "CPU Time: 0.056436 seconds\n",
            "GPU Time: 0.001316 seconds\n",
            "Speedup: 42.87x\n",
            "GPU Time sima + copia2: 0.101210 seconds\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "# Vector size\n",
        "N = 1 << 24\n",
        "\n",
        "# Create random vectors\n",
        "a_cpu = np.random.rand(N).astype(np.float32)\n",
        "b_cpu = np.random.rand(N).astype(np.float32)\n",
        "c_cpu = np.empty_like(a_cpu)\n",
        "\n",
        "# ----- CPU Computation -----\n",
        "start_cpu = time.time()\n",
        "c_cpu[:] = a_cpu + b_cpu\n",
        "end_cpu = time.time()\n",
        "cpu_time = end_cpu - start_cpu\n",
        "\n",
        "start_gpu_tot = time.time()\n",
        "\n",
        "# Move data to GPU\n",
        "a_gpu = cp.array(a_cpu)  # Copy from NumPy to CuPy\n",
        "b_gpu = cp.array(b_cpu)\n",
        "c_gpu = cp.empty_like(a_gpu) # Allocate\n",
        "c_gpu_np = np.empty_like(c_cpu)\n",
        "c_gpu_np = c_gpu_np.reshape(c_gpu.shape)\n",
        "\n",
        "# ----- GPU Computation -----\n",
        "\n",
        "start = cp.cuda.Event()\n",
        "end = cp.cuda.Event()\n",
        "\n",
        "#start_gpu = time.time()\n",
        "start.record()\n",
        "c_gpu[:] = a_gpu + b_gpu\n",
        "end.record()\n",
        "#cp.cuda.Device(0).synchronize()  # Ensure GPU computation is finished\n",
        "#end_gpu = time.time()\n",
        "#gpu_time = end_gpu - start_gpu\n",
        "\n",
        "# Validate results\n",
        "c_gpu_np[:] = c_gpu.get()  # Convert back to NumPy\n",
        "\n",
        "end_gpu_tot = time.time()\n",
        "\n",
        "gpu_time_tot = end_gpu_tot - start_gpu_tot\n",
        "gpu_time = cp.cuda.get_elapsed_time(start, end) / 1000\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(f\"N: {N}\")\n",
        "print(f\"CPU Time: {cpu_time:.6f} seconds\")\n",
        "print(f\"GPU Time: {gpu_time:.6f} seconds\")\n",
        "print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n",
        "print(f\"GPU Time sima + copia2: {gpu_time_tot:.6f} seconds\")\n",
        "\n",
        "assert np.allclose(c_cpu, c_gpu_np), \"Results do not match!\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apéndice"
      ],
      "metadata": {
        "id": "cbYoi-5E-1zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A veces, cuando uno copia codigo, aparece un error que se soluciona corriendo esto"
      ],
      "metadata": {
        "id": "CfeGy5Xk_eFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "Frll-dMWH16O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ver la placa y el compilador a disposición."
      ],
      "metadata": {
        "id": "fg-tQF2X_l5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdiDLwNYH8fX",
        "outputId": "245aa9f2-2423-40a1-8acc-4226af8148a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Mon Feb  3 18:54:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0             32W /   70W |     344MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solución\n",
        "\n",
        "Escribir soluciones aquí abajo."
      ],
      "metadata": {
        "id": "3_l9Btw_JW9U"
      }
    }
  ]
}